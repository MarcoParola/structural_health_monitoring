# **structural_health_monitoring**

## **Abstract**
The Structural Health Monitoring (SHM) through the use of data collected by sensors installed on a civil structures is an increasingly central topic. SHM aims to detect breaks and measure the degree of damage, in order to act in time with maintenance interventions. The research done in this area increasingly aims to introduce Machine Learning (ML) techniques to perform this task. Adopting a Supervised Learning (SL) approach allows to make a more accurate data analysis, in order to better understand the level of damage with respect to an Unsupervised Learning (UL) approach. The possibility of carrying out more in-depth analysis using a supervised approach has an important disadvantage: the difficulty of having available labeled data. After a description of the most adopted methods based on an UL approach and their limitations, Some Deep Learning (DL)-based techniques are leveraged to solve a Simulation-Based Classification (SBC) and Simulation-Based Regression (SBR) problems. A synthetic dataset was generated by exploiting some parametric Model Order Reduction (MOR) techniques, thanks to which we can simulate the behavior of the dynamic response of the sensors to the solicitations starting from a model of the structure. After proposing some DL architectures for SBC and SBR problems, an evaluation on their performance is done to study how they work on artificially corrupted data, which simulate some real distortions.

&nbsp;

## **Scenario** 
All methods proposed in this repo refer to the following scenario shown on the figure below: 2D frame of a two-floor building. 16 sensors are installed at different locations to monitor both the X and Y axis. The red circles mark the exact points of the sensor positioning, in each point are placed both a *displacement sensor* and an *accelerometer*.

![plot](./img/Sensors_position.png)

&nbsp;

## **Project structure**
The project is composed by the following files and folders:
* **data** is the folder where you have to put the data in npy format. you can download the dataset at the following link (TODO put the link to the dataset), unzip the folder and move the content in this folder
* **models** is the folder where you can save the models you train.
* **autoencoderds.ipynb** is a colab notebook containing the definition of three different types of autoencoder architectures: *Feedforward AE*, *Convolutional AE* and *Long Short Time Memory AE*. Each of these architectures is trained twice: the first time on uncorrupted data to have a benchmark, the second time on data where a low power and lossy network is simulated to evaluate the performance degradation in this other scenario.
* **convolutional_models.ipynb** is a colab notebook containing the definition of the convolutional architectures of the different classifiers and regressors and the training of them on both clean and corrupted data
* **testing_models.ipynb** is a colab notebook where we evaluate how models built in *convolutional_models.ipynb* perform when distortion levels vary
* **utils.ipynb** is a colab notebook that contains some utility methods. It is run at the beginning of every other colab notebook.

